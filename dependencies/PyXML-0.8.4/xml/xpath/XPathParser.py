#
# DO NOT EDIT THIS FILE!
#
# Parser generated by BisonGen on Fri Jun  1 02:04:24 2001.
#


# token definitions
DOUBLE_DOT = 257
DOUBLE_COLON = 258
AT = 259
LEFT_PAREN = 260
LEFT_SQUARE = 261
COMMA = 262
LITERAL = 263
NLITERAL = 264
VARIABLE_REFERENCE = 265
WILDCARD_NAME = 266
MULTIPLY_OPERATOR = 267
FUNCTION_NAME = 268
DOUBLE_SLASH = 269
NOT_EQUAL = 270
LESS_THAN = 271
GREATER_THAN = 272
LESS_THAN_EQUAL = 273
GREATER_THAN_EQUAL = 274
OR = 275
AND = 276
DIV = 277
MOD = 278
COMMENT = 279
TEXT = 280
PROCESSING_INSTRUCTION = 281
NODE = 282
ANCESTOR = 283
ANCESTOR_OR_SELF = 284
ATTRIBUTE = 285
CHILD = 286
DESCENDANT = 287
DESCENDANT_OR_SELF = 288
FOLLOWING = 289
FOLLOWING_SIBLING = 290
NAMESPACE = 291
PARENT = 292
PRECEDING = 293
PRECEDING_SIBLING = 294
SELF = 295
NODE_TYPE = 296
AXIS_NAME = 297
RELATIONAL_OP = 298
EQUALITY_OP = 299

# vector mapping lexer token numbers into internal token numbers
token_translations = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 47, 
48, 2, 55, 53, 56, 51, 46, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 52, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 49, 2, 50, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 54, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 
21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 
39, 40, 41, 42, 43, 44, 45]

YYTRANSLATE = lambda x: x > 299 and 85 or token_translations[x]

# vector of items of all rules.
rhs_tokens = [None,
              [59],
              [58],
              [46],
              [46, 59],
              [66],
              [60],
              [59, 46, 60],
              [67],
              [62, 63],
              [62, 63, 61],
              [68],
              [64],
              [61, 64],
              [43, 4],
              [69],
              [12],
              [42, 47, 48],
              [42, 47, 9, 48],
              [49, 65, 50],
              [70],
              [15, 59],
              [59, 15, 60],
              [51],
              [3],
              [52],
              [],
              [78],
              [11],
              [47, 70, 48],
              [9],
              [10],
              [72],
              [14, 47, 48],
              [14, 47, 73, 48],
              [74],
              [73, 53, 74],
              [70],
              [76],
              [75, 54, 76],
              [57],
              [77],
              [77, 46, 59],
              [77, 15, 59],
              [71],
              [71, 61],
              [79],
              [78, 21, 79],
              [80],
              [79, 22, 80],
              [81],
              [80, 45, 81],
              [82],
              [81, 44, 82],
              [83],
              [82, 55, 83],
              [82, 56, 83],
              [84],
              [83, 13, 84],
              [75],
              [56, 75],
              ]

# vector of line numbers and filename of all rules
rule_info = [": line 0",
             "XPath/XPathBase.bgen.frag: line 5",
             "XPath/XPathBase.bgen.frag: line 8",
             "XPath/XPathBase.bgen.frag: line 15",
             "XPath/XPathBase.bgen.frag: line 24",
             "XPath/XPathBase.bgen.frag: line 34",
             "XPath/XPathBase.bgen.frag: line 41",
             "XPath/XPathBase.bgen.frag: line 44",
             "XPath/XPathBase.bgen.frag: line 55",
             "XPath/XPathBase.bgen.frag: line 62",
             "XPath/XPathBase.bgen.frag: line 72",
             "XPath/XPathBase.bgen.frag: line 83",
             "XPath/XPathBase.bgen.frag: line 90",
             "XPath/XPathBase.bgen.frag: line 104",
             "XPath/XPathBase.bgen.frag: line 121",
             "XPath/XPathBase.bgen.frag: line 131",
             "XPath/XPathBase.bgen.frag: line 149",
             "XPath/XPathBase.bgen.frag: line 158",
             "XPath/XPathBase.bgen.frag: line 169",
             "XPath/XPathBase.bgen.frag: line 185",
             "XPath/XPathBase.bgen.frag: line 201",
             "XPath/XPathBase.bgen.frag: line 208",
             "XPath/XPathBase.bgen.frag: line 224",
             "XPath/XPathBase.bgen.frag: line 241",
             "XPath/XPathBase.bgen.frag: line 250",
             "XPath/XPathBase.bgen.frag: line 263",
             "XPath/XPathBase.bgen.frag: line 272",
             "XPath/XPathBase.bgen.frag: line 285",
             "XPath/XPathBase.bgen.frag: line 292",
             "XPath/XPathBase.bgen.frag: line 301",
             "XPath/XPathBase.bgen.frag: line 313",
             "XPath/XPathBase.bgen.frag: line 322",
             "XPath/XPathBase.bgen.frag: line 332",
             "XPath/XPathBase.bgen.frag: line 339",
             "XPath/XPathBase.bgen.frag: line 352",
             "XPath/XPathBase.bgen.frag: line 368",
             "XPath/XPathBase.bgen.frag: line 380",
             "XPath/XPathBase.bgen.frag: line 399",
             "XPath/XPathBase.bgen.frag: line 406",
             "XPath/XPathBase.bgen.frag: line 409",
             "XPath/XPathBase.bgen.frag: line 424",
             "XPath/XPathBase.bgen.frag: line 427",
             "XPath/XPathBase.bgen.frag: line 430",
             "XPath/XPathBase.bgen.frag: line 441",
             "XPath/XPathBase.bgen.frag: line 457",
             "XPath/XPathBase.bgen.frag: line 460",
             "XPath/XPathBase.bgen.frag: line 474",
             "XPath/XPathBase.bgen.frag: line 477",
             "XPath/XPathBase.bgen.frag: line 492",
             "XPath/XPathBase.bgen.frag: line 495",
             "XPath/XPathBase.bgen.frag: line 510",
             "XPath/XPathBase.bgen.frag: line 513",
             "XPath/XPathBase.bgen.frag: line 528",
             "XPath/XPathBase.bgen.frag: line 531",
             "XPath/XPathBase.bgen.frag: line 566",
             "XPath/XPathBase.bgen.frag: line 569",
             "XPath/XPathBase.bgen.frag: line 580",
             "XPath/XPathBase.bgen.frag: line 595",
             "XPath/XPathBase.bgen.frag: line 598",
             "XPath/XPathBase.bgen.frag: line 631",
             "XPath/XPathBase.bgen.frag: line 634",
             ]

# vector of string-names indexed by token number
token_names = ['$',
               'error',
               '$undefined.',
               'DOUBLE_DOT',
               'DOUBLE_COLON',
               'AT',
               'LEFT_PAREN',
               'LEFT_SQUARE',
               'COMMA',
               'LITERAL',
               'NLITERAL',
               'VARIABLE_REFERENCE',
               'WILDCARD_NAME',
               'MULTIPLY_OPERATOR',
               'FUNCTION_NAME',
               'DOUBLE_SLASH',
               'NOT_EQUAL',
               'LESS_THAN',
               'GREATER_THAN',
               'LESS_THAN_EQUAL',
               'GREATER_THAN_EQUAL',
               'OR',
               'AND',
               'DIV',
               'MOD',
               'COMMENT',
               'TEXT',
               'PROCESSING_INSTRUCTION',
               'NODE',
               'ANCESTOR',
               'ANCESTOR_OR_SELF',
               'ATTRIBUTE',
               'CHILD',
               'DESCENDANT',
               'DESCENDANT_OR_SELF',
               'FOLLOWING',
               'FOLLOWING_SIBLING',
               'NAMESPACE',
               'PARENT',
               'PRECEDING',
               'PRECEDING_SIBLING',
               'SELF',
               'NODE_TYPE',
               'AXIS_NAME',
               'RELATIONAL_OP',
               'EQUALITY_OP',
               '/',
               '(',
               ')',
               '[',
               ']',
               '.',
               '@',
               ',',
               '|',
               '+',
               '-',
               'locationPath',
               'absoluteLocationPath',
               'relativeLocationPath',
               'step',
               'predicateList',
               'axisSpecifier',
               'nodeTest',
               'predicate',
               'predicateExpr',
               'abbreviatedAbsoluteLocationPath',
               'abbreviatedRelativeLocationPath',
               'abbreviatedStep',
               'abbreviatedAxisSpecifier',
               'expr',
               'primaryExpr',
               'functionCall',
               'argumentList',
               'argument',
               'unionExpr',
               'pathExpr',
               'filterExpr',
               'orExpr',
               'andExpr',
               'equalityExpr',
               'relationalExpr',
               'additiveExpr',
               'multiplicativeExpr',
               'unaryExpr',
               '0',
               ]

# symbol number of symbol that rule derives.
derives = [0, 57, 57, 58, 58, 58, 59, 59, 59, 60, 60, 60, 61, 61, 62, 62, 
63, 63, 63, 64, 65, 66, 67, 68, 68, 69, 69, 70, 71, 71, 71, 71, 71, 72, 
72, 73, 73, 74, 75, 75, 76, 76, 76, 76, 77, 77, 78, 78, 79, 79, 80, 80, 
81, 81, 82, 82, 82, 83, 83, 84, 84]

# number of symbols composing right hand side of rule.
rhs_size = [0, 1, 1, 1, 2, 1, 1, 3, 1, 2, 3, 1, 1, 2, 2, 1, 1, 3, 4, 3, 
1, 2, 3, 1, 1, 1, 0, 1, 1, 3, 1, 1, 1, 3, 4, 1, 3, 1, 1, 3, 1, 1, 3, 3, 
1, 2, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 3, 1, 3, 1, 2]

# default rule to reduce with in state. 0 means the default is an error.
# indexed by state number
default_action = [26, 24, 30, 31, 28, 0, 26, 0, 3, 26, 23, 25, 26, 40, 
2, 1, 6, 0, 5, 8, 11, 15, 44, 32, 59, 38, 41, 27, 46, 48, 50, 52, 54, 57, 
26, 21, 14, 4, 0, 60, 26, 26, 16, 0, 9, 26, 45, 12, 26, 26, 26, 26, 26, 
26, 26, 26, 26, 26, 33, 37, 0, 35, 29, 22, 7, 0, 10, 0, 20, 13, 39, 43, 
42, 47, 49, 51, 53, 55, 56, 58, 34, 26, 0, 17, 19, 36, 18, 0, 0, 0]

# default state to go to after a reduction of a rule.
# indexed by variable number (lhs token)
default_goto = [13, 14, 15, 16, 46, 17, 44, 47, 67, 18, 19, 20, 21, 59, 
22, 23, 60, 61, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]

# index in yytable of the portion describing state (indexed by state number)
# If the value in yytable is positive, we shift the token and go to that state.
# If the value is negative, it is minus a rule number to reduce by.
# If the value is zero, the default action from yydefact[s] is used.
action_idx = [-3, -32768, -32768, -32768, -32768, -42, 13, 31, 43, -3, 
-32768, -32768, 66, -32768, -32768, -14, -32768, -8, -32768, -32768, -32768, 
-32768, -32, -32768, -23, -32768, -13, -2, 17, 6, 24, -46, 48, -32768, 
11, -14, -32768, -14, 34, -23, 47, 47, -32768, 37, -32, 27, -32, -32768, 
93, 49, 49, 27, 27, 27, 27, 27, 27, 27, -32768, -32768, -35, -32768, -32768, 
-32768, -32768, 18, -32, 41, -32768, -32768, -32768, -14, -14, 17, 6, 24, 
-46, 48, 48, -32768, -32768, 27, 45, -32768, -32768, -32768, -32768, 87, 
97, -32768]

# the index in yytable of the portion describing what to do after reducing a rule.
# The value from yytable is the state to go to.
goto_idx = [-32768, -32768, 39, -12, 61, -32768, -32768, -43, -32768, -32768, 
-32768, -32768, -32768, 15, -32768, -32768, -32768, 25, 98, 63, -32768, 
-32768, 64, 62, 67, 65, 16, 59]

# a vector filled with portions for different uses. (using action_idx and goto_idx)
yytable = [1, 40, 49, 69, 42, 34, 2, 3, 4, 55, 56, 5, 6, 80, 1, 87, 1, 
45, 81, 51, 2, 3, 4, 69, 38, 5, 6, 82, 63, 64, 1, 48, 41, 50, 43, 36, 2, 
3, 4, 52, 7, 5, 6, 8, 9, 35, 1, 37, 10, 11, 1, 53, 1, 12, 7, -26, 7, 8, 
9, 58, 68, 57, 10, 11, 10, 11, 83, 12, 54, 1, 7, 77, 78, 8, 9, 2, 3, 4, 
10, 11, 5, 6, 62, 12, 65, -26, 7, 88, 71, 72, 7, 84, 7, 86, 10, 11, 1, 
89, 10, 11, 10, 11, 2, 3, 4, 66, 85, 5, 6, 7, 39, 70, 8, 9, 74, 73, 79, 
10, 11, 76, 75, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 8, 
9, 0, 0, 0, 10, 11]

# a vector indexed in parallel with yytable.
# It indicates the bounds of the portion you are trying to examine.
yycheck = [3, 15, 15, 46, 12, 47, 9, 10, 11, 55, 56, 14, 15, 48, 3, 0, 
3, 49, 53, 21, 9, 10, 11, 66, 9, 14, 15, 9, 40, 41, 3, 54, 46, 46, 42, 
4, 9, 10, 11, 22, 43, 14, 15, 46, 47, 6, 3, 8, 51, 52, 3, 45, 3, 56, 43, 
12, 43, 46, 47, 48, 45, 13, 51, 52, 51, 52, 48, 56, 44, 3, 43, 55, 56, 
46, 47, 9, 10, 11, 51, 52, 14, 15, 48, 56, 47, 42, 43, 0, 49, 50, 43, 50, 
43, 48, 51, 52, 3, 0, 51, 52, 51, 52, 9, 10, 11, 44, 81, 14, 15, 43, 12, 
48, 46, 47, 52, 51, 57, 51, 52, 54, 53, -1, -1, -1, -1, -1, -1, -1, -1, 
-1, -1, -1, -1, -1, -1, -1, 43, -1, -1, 46, 47, -1, -1, -1, 51, 52]

YYLAST = 145
YYFINAL = 89
YYFLAG = -32768
YYNTBASE = 57

# Static definitions
YYEMPTY = -2
YYEOF = 0
YYINITDEPTH = 1000

LEXER_FUNCTIONS = 0

class Parser:
    def __init__(self, verbose=0):
        self.verbose = verbose
        
    def debug_mode(self, flag=None):
        if flag is None:
            return self.verbose

        if type(flag) != type(1):
            raise TypeError('an integer is required')
        self.verbose = flag
        return flag

    def parse(self, text):
        state_stack = [0]*YYINITDEPTH
        value_stack = [0]*YYINITDEPTH

        
        lexer_pos = 0
        lexer_end = len(text)
        lexer_state = INITIAL
        lexer_last = 0
        yylval = ''

        yyline = 1
        yycolumn = 1
        
        yystate = 0
        yychar = YYEMPTY        # cause a token to be read
        
        # Initialize stack pointers
        # Waste one element of value and location stack
        # so that they stay on the same level as the state stack.
        # The wasted elements are never initialized.
        state_ptr = -1
        value_ptr = 0
        
        while 1:
            # Push a new state, which is found in yystate.
            # In all cases, when you get here, the value and location stacks
            # have just been pushed.  So pushing a state here evens the stacks.
            state_ptr = state_ptr + 1
            state_stack[state_ptr] = yystate
        
            
            # Do appropriate processing given the current state.
            # Read a lookahead token if we need one and don't already have one.
        
            # First try to decide what to do without reference to lookahead token.
            yyn = action_idx[yystate]
            if yyn == YYFLAG:
                yyn = default_action[yystate]
                if yyn == 0:
                    self.report_error(yystate, yyline, yycolumn, yylval)
                    return 1
                # Do a reduction. yyn is the number of a rule to reduce with.
        
                state_ptr = state_ptr - rhs_size[yyn]
                value_ptr = value_ptr - rhs_size[yyn]
        
                if action_routines[yyn]:
                    yyval = action_routines[yyn](self, value_stack, value_ptr)
                    value_ptr = value_ptr + 1
                    value_stack[value_ptr] = yyval
                else:
                    value_ptr = value_ptr + 1

        
                # Now "shift" the result of the reduction.
                # Determine what state that goes to, based on the state
                # we popped back to and the rule number reduced by.
        
                yyn = derives[yyn] - YYNTBASE
                yystate = goto_idx[yyn] + state_stack[state_ptr]
                if 0 <= yystate <= YYLAST and yycheck[yystate] == state_stack[state_ptr]:
                    yystate = yytable[yystate]
                else:
                    yystate = default_goto[yyn]
                continue
            
            # Not known => get a lookahead token if don't already have one.
        
            # yychar is either YYEMPTY, YYEOF or a valid token in external form
            if yychar == YYEMPTY:
                # Setup line and column numbers
                for ch in yylval:
                    if ch == '\n':
                        yyline = yyline + 1
                        yycolumn = 1
                    else:
                        yycolumn = yycolumn + 1

                ### Lexical analysis ###
                while lexer_last < lexer_end:
                    lexer_pos = lexer_last
                    try:
                        match = patterns[lexer_state].match(text, lexer_pos)
                        matched = reduce(lambda result, item:
                                         item[1] is None and result or item,
                                         match.groupdict().items(),
                                         (None, None))
                    except AttributeError:
                        # comes here when match is none, it is an error anyway
                        self.error('No action found for "%s"' % text[lexer_pos:])

                    lexer_last = lexer_last + len(matched[1])
                    lexer_action = pattern_actions[matched[0]]
                    
                    if lexer_action:
                        lexer_state = lexer_action[0] or lexer_state
                        if len(lexer_action) > 1:
                            yylval = matched[1]
                            yychar = lexer_action[1] or ord(yylval)
                            break
                        else:
                            # Just a state change, reprocess the text
                            lexer_last = lexer_pos
                    else:
                        # throw away matched text and update position
                        for ch in matched[1]:
                            if ch == '\n':
                                yyline = yyline + 1
                                yycolumn = 1
                            else:
                                yycolumn = yycolumn + 1
                    continue
                else:
                    # Reached end of input
                    yychar = YYEOF
            # Convert token to internal form (in yychar1) for indexing tables with

            if yychar <= 0:
                # This means end-of-input.
                yychar1 = 0
            else:
                yychar1 = YYTRANSLATE(yychar)
                yyn = yyn + yychar1

            if yyn < 0 or yyn > YYLAST or  yycheck[yyn] != yychar1:
                # comes here after end of input
                yyn = default_action[yystate]
                if yyn == 0:
                    self.report_error(yystate, yyline, yycolumn, yylval)
                    return None
                # Do a reduction. yyn is the number of a rule to reduce with.
        
                state_ptr = state_ptr - rhs_size[yyn]
                value_ptr = value_ptr - rhs_size[yyn]
        
                if action_routines[yyn]:
                    yyval = action_routines[yyn](self, value_stack, value_ptr)
                    value_ptr = value_ptr + 1
                    value_stack[value_ptr] = yyval
                else:
                    value_ptr = value_ptr + 1

        
                # Now "shift" the result of the reduction.
                # Determine what state that goes to, based on the state
                # we popped back to and the rule number reduced by.
        
                yyn = derives[yyn] - YYNTBASE
                yystate = goto_idx[yyn] + state_stack[state_ptr]
                if 0 <= yystate <= YYLAST and yycheck[yystate] == state_stack[state_ptr]:
                    yystate = yytable[yystate]
                else:
                    yystate = default_goto[yyn]
                continue
            
            yyn = yytable[yyn]
        
            # yyn is what to do for this token type in this state.
            # Negative => reduce, -yyn is rule number.
            # Positive => shift, yyn is new state.
            #   New state is final state => don't bother to shift
            #   just return success.
            # 0, or max negative number => error.
        
            if YYFLAG < yyn < 0:
                yyn = -yyn
                # Do a reduction. yyn is the number of a rule to reduce with.
        
                state_ptr = state_ptr - rhs_size[yyn]
                value_ptr = value_ptr - rhs_size[yyn]
        
                if action_routines[yyn]:
                    yyval = action_routines[yyn](self, value_stack, value_ptr)
                    value_ptr = value_ptr + 1
                    value_stack[value_ptr] = yyval
                else:
                    value_ptr = value_ptr + 1

        
                # Now "shift" the result of the reduction.
                # Determine what state that goes to, based on the state
                # we popped back to and the rule number reduced by.
        
                yyn = derives[yyn] - YYNTBASE
                yystate = goto_idx[yyn] + state_stack[state_ptr]
                if 0 <= yystate <= YYLAST and yycheck[yystate] == state_stack[state_ptr]:
                    yystate = yytable[yystate]
                else:
                    yystate = default_goto[yyn]
                continue
            elif yyn == YYFINAL:
                return value_stack[value_ptr-1]
            elif yyn <= 0:
                # Now it is either 0 or YYFLAG
                self.report_error(yystate, yyline, yycolumn, yylval)
                return None
            
            # Shift the lookahead token.
        
 
            if yychar != YYEOF:
                yychar = YYEMPTY
            
            value_ptr = value_ptr + 1
            value_stack[value_ptr] = yylval
        
            yystate = yyn
            continue
        # should never get here
        return None
        
    def report_error(self, state, line, column, lval):
        ruleno = action_idx[state]
        msg = "parse error at line %d, column %d: matched '%s'" % (
            line, column, lval)
        if YYFLAG < ruleno < YYLAST:
            # Start X at -ruleno to avoid negative indexes in yycheck
            start = ruleno < 0 and -ruleno or 0
            first = 1
            for x in range(start, len(token_names)):
                if (x + ruleno) < len(yycheck) and yycheck[x + ruleno] == x:
                    if first:
                        msg = msg + ", expecting"
                        first = 0
                    else:
                        msg = msg + " or"
                    msg = msg + " '%s'" % token_names[x]
        self.error(msg)
        return
        
    def announce(self, format, *args):
        sys.stderr.write(format % args)
        return

    def error(self, format, *args):
        raise SyntaxError(format % args)

    def print_reduce(self, rule):
        sys.stderr.write("Reducing via rule %d (%s), " % (rule, rule_info[rule]))
        # print the symbols being reduced and their result.
        for token in rhs_tokens[rule]:
            sys.stderr.write("%s " % token_names[token])
        sys.stderr.write("-> %s\n" % token_names[derives[rule]])
        return

    def print_state_stack(self, stack, size):
        sys.stderr.write("state stack now")
        for i in range(size+1):
            sys.stderr.write(" %d" % stack[i])
        sys.stderr.write("\n")
        return

new = Parser

# modules required for action routines
from xml.xpath import ParsedAbsoluteLocationPath
from xml.xpath import ParsedRelativeLocationPath
from xml.xpath import ParsedPredicateList
from xml.xpath import ParsedStep
from xml.xpath import ParsedAxisSpecifier
from xml.xpath import ParsedNodeTest
from xml.xpath import ParsedAbbreviatedAbsoluteLocationPath
from xml.xpath import ParsedAbbreviatedRelativeLocationPath
from xml.xpath import ParsedExpr

# the action code for each rule
def absoluteLocationPath1(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 15
    absoluteLocationPath: '/'
    """
    __val = ParsedAbsoluteLocationPath.ParsedAbsoluteLocationPath(None)
    return __val

def absoluteLocationPath2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 24
    absoluteLocationPath: '/' relativeLocationPath
    """
    __val = ParsedAbsoluteLocationPath.ParsedAbsoluteLocationPath(__stack[__ptr+2])
    return __val

def relativeLocationPath2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 44
    relativeLocationPath: relativeLocationPath '/' step
    """
    __val = ParsedRelativeLocationPath.ParsedRelativeLocationPath(__stack[__ptr+1], __stack[__ptr+3])
    return __val

def step1(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 62
    step: axisSpecifier nodeTest
    """
    __val = ParsedStep.ParsedStep(__stack[__ptr+1], __stack[__ptr+2])
    return __val

def step2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 72
    step: axisSpecifier nodeTest predicateList
    """
    __val = ParsedStep.ParsedStep(__stack[__ptr+1], __stack[__ptr+2], __stack[__ptr+3])
    return __val

def predicateList1(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 90
    predicateList: predicate
    """
    __val = ParsedPredicateList.ParsedPredicateList([__stack[__ptr+1]])
    return __val

def predicateList2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 104
    predicateList: predicateList predicate
    """
    __stack[__ptr+1].append(__stack[__ptr+2])
    __val = __stack[__ptr+1]
    return __val

def axisSpecifier1(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 121
    axisSpecifier: AXIS_NAME DOUBLE_COLON
    """
    __val = ParsedAxisSpecifier.ParsedAxisSpecifier(__stack[__ptr+1])
    return __val

def nodeTest1(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 149
    nodeTest: WILDCARD_NAME
    """
    __val = ParsedNodeTest.ParsedNameTest(__stack[__ptr+1])
    return __val

def nodeTest2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 158
    nodeTest: NODE_TYPE '(' ')'
    """
    __val = ParsedNodeTest.ParsedNodeTest(__stack[__ptr+1])
    return __val

def nodeTest3(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 169
    nodeTest: NODE_TYPE '(' LITERAL ')'
    """
    __val = ParsedNodeTest.ParsedNodeTest(__stack[__ptr+1], __stack[__ptr+3])
    return __val

def predicate1(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 185
    predicate: '[' predicateExpr ']'
    """
    __val = __stack[__ptr+2]
    return __val

def abbreviatedAbsoluteLocationPath1(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 208
    abbreviatedAbsoluteLocationPath: DOUBLE_SLASH relativeLocationPath
    """
    __val = ParsedAbbreviatedAbsoluteLocationPath.ParsedAbbreviatedAbsoluteLocationPath(__stack[__ptr+2])
    return __val

def abbreviatedRelativeLocationPath1(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 224
    abbreviatedRelativeLocationPath: relativeLocationPath DOUBLE_SLASH step
    """
    __val = ParsedAbbreviatedRelativeLocationPath.ParsedAbbreviatedRelativeLocationPath(__stack[__ptr+1], __stack[__ptr+3])
    return __val

def abbreviatedStep1(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 241
    abbreviatedStep: '.'
    """
    __val = ParsedStep.ParsedAbbreviatedStep(0)
    return __val

def abbreviatedStep2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 250
    abbreviatedStep: DOUBLE_DOT
    """
    __val = ParsedStep.ParsedAbbreviatedStep(1)
    return __val

def abbreviatedAxisSpecifier1(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 263
    abbreviatedAxisSpecifier: '@'
    """
    __val = ParsedAxisSpecifier.ParsedAxisSpecifier("attribute")
    return __val

def abbreviatedAxisSpecifier2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 272
    abbreviatedAxisSpecifier:
    """
    __val = ParsedAxisSpecifier.ParsedAxisSpecifier("child")
    return __val

def primaryExpr1(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 292
    primaryExpr: VARIABLE_REFERENCE
    """
    __val = ParsedExpr.ParsedVariableReferenceExpr(__stack[__ptr+1])
    return __val

def primaryExpr2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 301
    primaryExpr: '(' expr ')'
    """
    __val = __stack[__ptr+2]
    return __val

def primaryExpr3(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 313
    primaryExpr: LITERAL
    """
    __val = ParsedExpr.ParsedLiteralExpr(__stack[__ptr+1])
    return __val

def primaryExpr4(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 322
    primaryExpr: NLITERAL
    """
    __val = ParsedExpr.ParsedNLiteralExpr(__stack[__ptr+1])
    return __val

def functionCall1(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 339
    functionCall: FUNCTION_NAME '(' ')'
    """
    __val = ParsedExpr.ParsedFunctionCallExpr(__stack[__ptr+1], [])
    return __val

def functionCall2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 352
    functionCall: FUNCTION_NAME '(' argumentList ')'
    """
    __val = ParsedExpr.ParsedFunctionCallExpr(__stack[__ptr+1], __stack[__ptr+3])
    return __val

def argumentList1(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 368
    argumentList: argument
    """
    __val = [__stack[__ptr+1]]
    return __val

def argumentList2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 380
    argumentList: argumentList ',' argument
    """
    __stack[__ptr+1].append(__stack[__ptr+3])
    __val = __stack[__ptr+1]
    return __val

def unionExpr2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 409
    unionExpr: unionExpr '|' pathExpr
    """
    __val = ParsedExpr.ParsedUnionExpr(__stack[__ptr+1], __stack[__ptr+3])
    return __val

def pathExpr3(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 430
    pathExpr: filterExpr '/' relativeLocationPath
    """
    __val = ParsedExpr.ParsedPathExpr(__stack[__ptr+2], __stack[__ptr+1], __stack[__ptr+3])
    return __val

def pathExpr4(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 441
    pathExpr: filterExpr DOUBLE_SLASH relativeLocationPath
    """
    __val = ParsedExpr.ParsedPathExpr(__stack[__ptr+2], __stack[__ptr+1], __stack[__ptr+3])
    return __val

def filterExpr2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 460
    filterExpr: primaryExpr predicateList
    """
    __val = ParsedExpr.ParsedFilterExpr(__stack[__ptr+1], __stack[__ptr+2])
    return __val

def orExpr2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 477
    orExpr: orExpr OR andExpr
    """
    __val = ParsedExpr.ParsedOrExpr(__stack[__ptr+1], __stack[__ptr+3])
    return __val

def andExpr2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 495
    andExpr: andExpr AND equalityExpr
    """
    __val = ParsedExpr.ParsedAndExpr(__stack[__ptr+1], __stack[__ptr+3])
    return __val

def equalityExpr2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 513
    equalityExpr: equalityExpr EQUALITY_OP relationalExpr
    """
    __val = ParsedExpr.ParsedEqualityExpr(__stack[__ptr+2], __stack[__ptr+1], __stack[__ptr+3])
    return __val

def relationalExpr2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 531
    relationalExpr: relationalExpr RELATIONAL_OP additiveExpr
    """
    ops = {'<' : 0,
           '>' : 2,
           '<=' : 1,
           '>=' : 3,
           }
    __val = ParsedExpr.ParsedRelationalExpr(ops[__stack[__ptr+2]], __stack[__ptr+1], __stack[__ptr+3])
    return __val

def additiveExpr2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 569
    additiveExpr: additiveExpr '+' multiplicativeExpr
    """
    __val = ParsedExpr.ParsedAdditiveExpr(1, __stack[__ptr+1], __stack[__ptr+3])
    return __val

def additiveExpr3(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 580
    additiveExpr: additiveExpr '-' multiplicativeExpr
    """
    __val = ParsedExpr.ParsedAdditiveExpr(-1, __stack[__ptr+1], __stack[__ptr+3])
    return __val

def multiplicativeExpr2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 598
    multiplicativeExpr: multiplicativeExpr MULTIPLY_OPERATOR unaryExpr
    """
    ops = {'*' : 0,
           'div' : 1,
           'mod' : 2,
           }
    __val = ParsedExpr.ParsedMultiplicativeExpr(ops[__stack[__ptr+2]], __stack[__ptr+1], __stack[__ptr+3])
    return __val

def unaryExpr2(self, __stack, __ptr):
    """
    from XPath/XPathBase.bgen.frag, line 634
    unaryExpr: '-' unionExpr
    """
    __val = ParsedExpr.ParsedUnaryExpr(__stack[__ptr+2])
    return __val

action_routines = [None,
                   None,
                   None,
                   absoluteLocationPath1,
                   absoluteLocationPath2,
                   None,
                   None,
                   relativeLocationPath2,
                   None,
                   step1,
                   step2,
                   None,
                   predicateList1,
                   predicateList2,
                   axisSpecifier1,
                   None,
                   nodeTest1,
                   nodeTest2,
                   nodeTest3,
                   predicate1,
                   None,
                   abbreviatedAbsoluteLocationPath1,
                   abbreviatedRelativeLocationPath1,
                   abbreviatedStep1,
                   abbreviatedStep2,
                   abbreviatedAxisSpecifier1,
                   abbreviatedAxisSpecifier2,
                   None,
                   primaryExpr1,
                   primaryExpr2,
                   primaryExpr3,
                   primaryExpr4,
                   None,
                   functionCall1,
                   functionCall2,
                   argumentList1,
                   argumentList2,
                   None,
                   None,
                   unionExpr2,
                   None,
                   None,
                   pathExpr3,
                   pathExpr4,
                   None,
                   filterExpr2,
                   None,
                   orExpr2,
                   None,
                   andExpr2,
                   None,
                   equalityExpr2,
                   None,
                   relationalExpr2,
                   None,
                   additiveExpr2,
                   additiveExpr3,
                   None,
                   multiplicativeExpr2,
                   None,
                   unaryExpr2,
                   ]

# start condition definitions for the lexer
INITIAL = 1
OPERATOR = 2

# the expressions and information for each rule
import re
patterns = {
    INITIAL : re.compile('(?P<p00>\\)|\\])|(?P<p01>::)|(?P<p02>\\.\\.)|(?P<p03>//)|(?P<p04>=|!=)|(?P<p05><=|<|>=|>)|(?P<p06>(node|text|comment|processing-instruction)(?=\\s*\\())|(?P<p07>[a-zA-Z_][a-zA-Z0-9\\.\\-_]*(?=\\s*::))|(?P<p08>(\'[^\']*\')|("[^"]*"))|(?P<p09>(\\d+(\\.(\\d+)?)?)|(\\.\\d+))|(?P<p10>\\$([a-zA-Z_][a-zA-Z0-9\\.\\-_]*:)?[a-zA-Z_][a-zA-Z0-9\\.\\-_]*)|(?P<p11>([a-zA-Z_][a-zA-Z0-9\\.\\-_]*:)?[a-zA-Z_][a-zA-Z0-9\\.\\-_]*(?=\\s*\\())|(?P<p12>([a-zA-Z_][a-zA-Z0-9\\.\\-_]*:\\*)|(([a-zA-Z_][a-zA-Z0-9\\.\\-_]*:)?[a-zA-Z_][a-zA-Z0-9\\.\\-_]*)|\\*)|(?P<p13>[\\t\\n\\r\\s]+)|(?P<p14>.)', re.M),
    OPERATOR : re.compile('(?P<p15>or)|(?P<p16>and)|(?P<p17>\\*|mod|div)|(?P<p18>[\\t\\n\\r\\s]+)|(?P<p19>.)', re.M),
}
pattern_actions = {
    'p00' : (OPERATOR, None),
    'p01' : (INITIAL, DOUBLE_COLON),
    'p02' : (INITIAL, DOUBLE_DOT),
    'p03' : (INITIAL, DOUBLE_SLASH),
    'p04' : (INITIAL, EQUALITY_OP),
    'p05' : (INITIAL, RELATIONAL_OP),
    'p06' : (None, NODE_TYPE),
    'p07' : (None, AXIS_NAME),
    'p08' : (OPERATOR, LITERAL),
    'p09' : (OPERATOR, NLITERAL),
    'p10' : (OPERATOR, VARIABLE_REFERENCE),
    'p11' : (None, FUNCTION_NAME),
    'p12' : (OPERATOR, WILDCARD_NAME),
    'p13' : None,
    'p14' : (INITIAL, None),
    'p15' : (INITIAL, OR),
    'p16' : (INITIAL, AND),
    'p17' : (INITIAL, MULTIPLY_OPERATOR),
    'p18' : None,
    'p19' : (INITIAL, ),
}
if __name__ == '__main__':
    import sys
    try: import readline
    except: pass

    try:
        import XPathParserc
        parser = XPathParserc.new(1)
        print 'Using C parser'
    except:
        import XPathParser
        parser = XPathParser.new(1)
        print 'Using Python parser'

    if len(sys.argv) > 1:
        result = parser.parse(sys.argv[1])
        result.pprint()
        raise SystemExit()
    print 'Use <Ctrl>-C to exit.'
    try:
        while 1:
            expr = raw_input('>>>')
            result = parser.parse(expr)
            result.pprint()
    except KeyboardInterrupt:
        raise SystemExit
